{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rQYKu6LRsEUK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "s7JABsj-sEsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd  # Import pandas for data manipulation\n",
        "import numpy as np  # Import numpy for numerical computations\n",
        "import matplotlib.pyplot as plt  # Import matplotlib for data visualization\n",
        "from sklearn.ensemble import RandomForestClassifier  # Import RandomForestClassifier from scikit-learn\n",
        "from sklearn.metrics import accuracy_score  # Import accuracy_score metric from scikit-learn\n",
        "from sklearn.model_selection import train_test_split  # Import train_test_split for data splitting\n",
        "from sklearn.impute import SimpleImputer  # Import SimpleImputer for handling missing values\n",
        "import joblib  # Import joblib for model persistence\n",
        "import logging  # Import logging for logging events\n",
        "import time  # Import time for time-related operations\n",
        "\n",
        "titanic_data = pd.read_csv('data/titanic.csv')  # Read Titanic dataset into a pandas DataFrame\n",
        "print(titanic_data.head())  # Display the first few rows of the dataset\n",
        "\n",
        "features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex', 'Embarked']  # Define features for modeling\n",
        "X = titanic_data[features]  # Assign features to X\n",
        "y = titanic_data['Survived']  # Assign target variable to y\n",
        "\n",
        "X = pd.get_dummies(X, columns=['Sex', 'Embarked'], drop_first=True)  # Perform one-hot encoding for categorical variables\n",
        "\n",
        "imputer = SimpleImputer(strategy='median')  # Initialize imputer for handling missing values using median strategy\n",
        "numerical_cols = ['Age', 'Fare']  # Specify numerical columns for imputation\n",
        "X[numerical_cols] = imputer.fit_transform(X[numerical_cols])  # Impute missing values in specified numerical columns\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)  # Split data into train and validation sets\n",
        "\n",
        "model = RandomForestClassifier()  # Initialize RandomForestClassifier model\n",
        "model.fit(X_train, y_train)  # Train the model on the training data\n",
        "\n",
        "joblib.dump(model, 'model/model.joblib')  # Save the trained model to a file\n",
        "\n",
        "logging.basicConfig(filename='real_time_model.log', level=logging.INFO, format='%(asctime)s - %(levelname)s: %(message)s')  # Configure logging settings\n",
        "\n",
        "predictions_list = []  # Initialize a list to store model accuracy predictions\n",
        "\n",
        "while True:  # Create an infinite loop for real-time updates\n",
        "    model.fit(X_train, y_train)  # Retrain the model on new data\n",
        "\n",
        "    y_pred_val = model.predict(X_val)  # Predict on the validation set\n",
        "    accuracy_val = accuracy_score(y_val, y_pred_val)  # Calculate accuracy on validation set\n",
        "    predictions_list.append(accuracy_val)  # Store the accuracy value in the predictions list\n",
        "\n",
        "    logging.info(f\"Real-Time Model Accuracy: {accuracy_val:.2f}\")  # Log the real-time model accuracy\n",
        "\n",
        "    plt.figure(figsize=(10, 5))  # Create a plot for real-time predictions visualization\n",
        "    plt.plot(predictions_list, marker='o', linestyle='-', color='b')  # Plot accuracy predictions\n",
        "    plt.title('Real-Time Model Predictions')  # Set title for the plot\n",
        "    plt.xlabel('Updates')  # Set label for x-axis\n",
        "    plt.ylabel('Accuracy')  # Set label for y-axis\n",
        "    plt.grid(True)  # Enable grid in the plot\n",
        "    plt.show()  # Display the plot\n",
        "\n",
        "    time.sleep(60)  # Pause for 60 seconds before the next update\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from flask import Flask, request, jsonify  # Import necessary Flask modules\n",
        "\n",
        "import joblib  # Import the joblib module for model loading\n",
        "\n",
        "app = Flask(__name__)  # Initialize a Flask web application\n",
        "\n",
        "model = joblib.load('model/model.joblib')  # Load the trained machine learning model\n",
        "\n",
        "@app.route('/predict', methods=['GET', 'POST'])  # Define an endpoint '/predict' that accepts GET and POST requests\n",
        "def predict():\n",
        "    if request.method == 'POST':  # Check if the request method is POST\n",
        "        data = request.get_json()  # Get JSON data from the POST request\n",
        "        features = data['features']  # Extract features from the received JSON data\n",
        "        prediction = model.predict([features])[0]  # Use the model to predict based on the provided features\n",
        "        return jsonify({'prediction': int(prediction)})  # Return the prediction as JSON\n",
        "    else:\n",
        "        return \"This endpoint accepts POST requests only.\"  # Return a message for GET requests\n",
        "\n",
        "if __name__ == '__main__':  # Start the Flask application if this script is executed directly\n",
        "    app.run(debug=True)  # Run the Flask application in debug mode"
      ],
      "metadata": {
        "id": "kwhv1QihsHYz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}